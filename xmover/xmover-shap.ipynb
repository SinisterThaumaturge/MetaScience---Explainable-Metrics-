{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./xmover')\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "import shap\n",
    "from mosestokenizer import MosesDetokenizer, MosesTokenizer\n",
    "from scorer import XMOVERScorer\n",
    "import torch\n",
    "import truecase\n",
    "from xmovershapnew import ExplainableXMover\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "RESULTS_FNAME = 'results.json'\n",
    "SRC_LANG = 'et'\n",
    "TGT_LANG = 'en'\n",
    "SPLIT = 'dev'\n",
    "data_dir = f'../../data/{SPLIT}/{SRC_LANG}-{TGT_LANG}-{SPLIT}'\n",
    "src = [s.strip() for s in open(f'{data_dir}/{SPLIT}.src').readlines()]\n",
    "tgt = [s.strip() for s in open(f'{data_dir}/{SPLIT}.mt').readlines()]\n",
    "wor = [list(map(int, s.strip().split())) for s in open(f'{data_dir}/{SPLIT}.tgt-tags').readlines()]\n",
    "sen = [float(s.strip()) for s in open(f'{data_dir}/{SPLIT}.da').readlines()]\n",
    "assert len(src) == len(tgt) == len(wor) == len(sen)\n",
    "dataset = {'src': src, 'tgt': tgt, 'word_labels': wor, 'sent_labels': sen}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get XMover Explainer to Rate and Explain\n",
    "This step can cost quite some time: on a 6-core workstation with a single RTX 2080 GPU card, explaining each translation costs around 3 seconds on average. Hence, explaining all 1000 cases in the dev set takes around 1 hour to finish."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = ExplainableXMover(SRC_LANG, TGT_LANG)\n",
    "import time\n",
    "exps = []\n",
    "for i in tqdm(range(10)):\n",
    "    score = model(dataset['src'][i], dataset['tgt'][i]) # uncomment this line if you also want the xmover-score\n",
    "    runtimer = time.time()\n",
    "    exp = model.explain(dataset['src'][i], dataset['tgt'][i])\n",
    "    runtimer= time.time() - runtimer\n",
    "    exps.append(\n",
    "            {\n",
    "                'pred': float(exp),\n",
    "                'time': runtimer\n",
    "            }\n",
    "        )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12\n",
      "./xmover/mapping/layer-12/europarl-v7.et-en.2k.12.BAM.map\n",
      "./xmover/mapping/layer-12/europarl-v7.et-en.2k.12.GBDD.map\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ec1fed67a444253bf5be6011f85a3a7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len trna1\n",
      "1\n",
      "len trna\n",
      "1\n",
      "len xmovers\n",
      "1\n",
      "len trna1\n",
      "27\n",
      "len trna\n",
      "27\n",
      "len xmovers\n",
      "27\n",
      "len trna1\n",
      "27\n",
      "len trna\n",
      "27\n",
      "len xmovers\n",
      "27\n",
      "len trna1\n",
      "27\n",
      "len trna\n",
      "27\n",
      "len xmovers\n",
      "27\n",
      "len trna1\n",
      "27\n",
      "len trna\n",
      "27\n",
      "len xmovers\n",
      "27\n",
      "len trna1\n",
      "27\n",
      "len trna\n",
      "27\n",
      "len xmovers\n",
      "27\n",
      "len trna1\n",
      "27\n",
      "len trna\n",
      "27\n",
      "len xmovers\n",
      "27\n",
      "len trna1\n",
      "27\n",
      "len trna\n",
      "27\n",
      "len xmovers\n",
      "27\n",
      "len trna1\n",
      "27\n",
      "len trna\n",
      "27\n",
      "len xmovers\n",
      "27\n",
      "len trna1\n",
      "27\n",
      "len trna\n",
      "27\n",
      "len xmovers\n",
      "27\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'list'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0a461b0ea403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     exps.append(\n\u001b[1;32m     10\u001b[0m             {\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0;34m'pred'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;34m'time'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mruntimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             }\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# optional: save the explanations\n",
    "import pickle\n",
    "with open('et-en_exps.pkl','wb') as ff:\n",
    "    pickle.dump(exps, ff)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the Quality of the Explanations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# if you have saved some explanations, you can load them\n",
    "import pickle\n",
    "exps = pickle.load(open('et-en_exps.pkl','rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "exp_scores = []\n",
    "for exp in exps:\n",
    "    scores = [-entry[1] for entry in exp] # use negative SHAP values to find the incorrect tokens\n",
    "    exp_scores.append(scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "sys.path.append('../..')\n",
    "from scripts.evaluate import evaluate_word_level\n",
    "\n",
    "evaluate_word_level(dataset['word_labels'], exp_scores)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AUC score: 0.583\n",
      "AP score: 0.456\n",
      "Recall at top-K: 0.352\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('deeplearning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "interpreter": {
   "hash": "1e44300418bea9fe154b6649c63a84ca2ac6e6076df703d84bbdba8f529e8cfc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}